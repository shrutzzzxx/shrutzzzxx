{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "159e0253-719b-4abd-9777-b21822ee854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11e95ea4-d1c2-4202-b2f4-5455254321af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc08e91-a570-4001-8723-3b5d89b0a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer \n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9fdf088-2c20-49aa-af36-f8efa9ccbc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eating | eat\n",
      "Sleeping | sleep\n",
      "Dancing | danc\n",
      "Jumping | jump\n",
      "Jumps | jump\n",
      "ate | ate\n",
      "ability | abil\n"
     ]
    }
   ],
   "source": [
    "words = [\"Eating\", \"Sleeping\", \"Dancing\" , \"Jumping\", \"Jumps\", \"ate\", \"ability\"]\n",
    "for word in words: \n",
    "    print(word, \"|\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2bef0c7-9897-4d63-9555-f92a492f104b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eating | eat | 9837207709914848172\n",
      "Sleeping | sleep | 9840574412351606749\n",
      "Dancing | Dancing | 16118941614785288017\n",
      "Jumping | Jumping | 13951021020171923904\n",
      "Jumps | Jumps | 10481887347433522086\n",
      "ate | eat | 9837207709914848172\n",
      "ability | ability | 11565809527369121409\n",
      "avengers | avenger | 4767041701466013365\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Eating Sleeping Dancing Jumping Jumps ate ability avengers\") \n",
    "for token in doc:\n",
    "    print(token, \"|\", token.lemma_, \"|\" ,token.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "332bade7-befd-4c94-b652-ee2a824eb684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mando | mando\n",
      "talked | talk\n",
      "for | for\n",
      "3 | 3\n",
      "days | day\n",
      "although | although\n",
      "talking | talk\n",
      "is | be\n",
      "n't | not\n",
      "his | his\n",
      "thing | thing\n",
      "he | he\n",
      "became | become\n",
      "talkative | talkative\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"mando talked for 3 days although talking isn't his thing he became talkative\")\n",
    "for token in doc: \n",
    "    print(token, \"|\", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41052da3-f5a8-413f-b50f-3b923cf22e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro | bro\n",
      ", | ,\n",
      "you | you\n",
      "wanna | wanna\n",
      "go | go\n",
      "? | ?\n",
      ", | ,\n",
      "Brah | Brah\n",
      ", | ,\n",
      "do | do\n",
      "n't | not\n",
      "say | say\n",
      "no | no\n",
      "! | !\n",
      ", | ,\n",
      "I | I\n",
      "am | be\n",
      "exhausted | exhaust\n"
     ]
    }
   ],
   "source": [
    "#customizing behaviour \n",
    "doc = nlp(\"Bro, you wanna go?, Brah, don't say no!, I am exhausted\")\n",
    "for token in doc: \n",
    "    print(token, \"|\", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d355c0b-568c-4984-a9ca-2a3bfc2db8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bro"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19fe5b53-df1c-4bdf-b998-07874c8cf7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bro'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0907f7a7-2f52-4167-9484-2c9d37ec0b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro | Brother\n",
      ", | ,\n",
      "you | you\n",
      "wanna | wanna\n",
      "go | go\n",
      "? | ?\n",
      ", | ,\n",
      "Brah | Brother\n",
      ", | ,\n",
      "do | do\n",
      "n't | not\n",
      "say | say\n",
      "no | no\n",
      "! | !\n",
      ", | ,\n",
      "I | I\n",
      "am | be\n",
      "exhausted | exhaust\n"
     ]
    }
   ],
   "source": [
    "#customizing \n",
    "ar = nlp.get_pipe('attribute_ruler')\n",
    "ar.add([[{\"TEXT\" : \"Bro\"}],[{\"TEXT\" : \"Brah\"}]], {\"LEMMA\": \"Brother\"})\n",
    "doc = nlp(\"Bro, you wanna go?, Brah, don't say no!, I am exhausted\")\n",
    "for token in doc: \n",
    "    print(token, \"|\", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96d129af-ba2a-485f-8c14-fc4af44732da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brother'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d93e61f0-57cb-4ecd-89c8-5e569d74b421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running | run\n",
      "painting | paint\n",
      "walking | walk\n",
      "dressing | dress\n",
      "likely | like\n",
      "children | children\n",
      "whom | whom\n",
      "good | good\n",
      "ate | ate\n",
      "fishing | fish\n"
     ]
    }
   ],
   "source": [
    "#exercise 1 \n",
    "\n",
    "lst_words = ['running', 'painting', 'walking', 'dressing', 'likely', 'children','whom', 'good', 'ate', 'fishing']\n",
    "for word in lst_words: \n",
    "    print(word, \"|\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "029ce9f1-f357-44f3-9f77-1185e4cd9bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running | run | 12767647472892411841\n",
      "painting | paint | 16929211676819693673\n",
      "walking | walk | 1674876016505392235\n",
      "dressing | dress | 12815368344456308931\n",
      "likely | likely | 6740298879949941214\n",
      "children | child | 737253710922290542\n",
      "who | who | 3876862883474502309\n",
      "good | good | 5711639017775284443\n",
      "ate | eat | 9837207709914848172\n",
      "fishing | fishing | 10959402079719336560\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"running painting walking dressing likely children who good ate fishing\")\n",
    "for token in doc:\n",
    "    print(token, \"|\", token.lemma_, \"|\" ,token.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "798f13fe-6170-48ab-845e-e105c3182a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exercise 2 \n",
    "text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a \n",
    "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbdccc34-b8be-4aca-bf83-73e5e813739a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latha is veri multi talent girl.sh is good at mani skill like danc , run , sing , playing.sh also like eat pav bhagi . she ha a habit of fish and swim too.besid all thi , she is a wonder at cook too .\n"
     ]
    }
   ],
   "source": [
    "#using stemming in nltk\n",
    "\n",
    "#step1: Word tokenizing\n",
    "all_word_tokens = nltk.word_tokenize(text)\n",
    "#step2: getting the base form for each token using stemmer\n",
    "all_base_words = []\n",
    "\n",
    "for token in all_word_tokens:\n",
    "  base_form = stemmer.stem(token)\n",
    "  all_base_words.append(base_form)\n",
    "#step3: joining all words in a list into string using 'join()'\n",
    "final_base_text = ' '.join(all_base_words)\n",
    "print(final_base_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d735b709-b6e2-4046-ba81-9bd1be868c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latha be very multi talented girl . she be good at many skill like dancing , running , singing , play . she also like eat Pav Bhagi . she have a \n",
      " habit of fishing and swim too . besides all this , she be a wonderful at cook too . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using lemmatisation in spacy\n",
    "\n",
    "\n",
    "#step1: Creating the object for the given text\n",
    "doc = nlp(text)\n",
    "all_base_words = []\n",
    "\n",
    "#step2: getting the base form for each token using spacy 'lemma_'\n",
    "for token in doc:\n",
    "  base_word =  token.lemma_\n",
    "  all_base_words.append(base_word)\n",
    "\n",
    "\n",
    "#step3: joining all words in a list into string using 'join()'\n",
    "final_base_text = ' '.join(all_base_words)\n",
    "print(final_base_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
